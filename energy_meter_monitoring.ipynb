{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgFZlT_g8O1Y"
      },
      "source": [
        "# Systems for Processing Big Data\n",
        "## TP1 - Energy Meter Monitoring\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRDJq9dL0GWA"
      },
      "source": [
        "\n",
        "\n",
        "The sensor data corresponds to regular readings from 11 residential energy meters. The data covers the month of February 2024.\n",
        "\n",
        "Each data sample has the following schema:\n",
        "\n",
        "timestamp | sensor_id | energy\n",
        "----------|-------------|-----------\n",
        "timestamp | string  | float\n",
        "\n",
        "Each energy value (KWh) corresponds to the accumulated value of the meter at the time of measurement. As such,\n",
        "each meter is expected to produce a monotonically increasing series of pairs of timestamp and energy consummed up to that moment.\n",
        "\n",
        "The meters do not start at zero or at the same value.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HC6tMDOU7Fdb"
      },
      "source": [
        "## Questions\n",
        "\n",
        "The following questions should be answered for the month of February and only for this month.\n",
        "\n",
        "### For the group of sensors:\n",
        "\n",
        "1. Compute the total energy consumed.\n",
        "\n",
        "2. Compute the running total energy consumed so far for each day, inclusive.\n",
        "\n",
        "Note: You can approximate the result but using the last reading of each day from each sensor.\n",
        "\n",
        "### For each sensor, separately:\n",
        "\n",
        "3. Compute the total energy consumed and the average energy consumption per day.\n",
        "\n",
        "4. Compute the day of the month with minimum and maximum energy consumption.\n",
        "\n",
        "Note: You can approximate the result but using the last reading of each day from each sensor.\n",
        "\n",
        "### For each sensor, separately, with estimations:\n",
        "\n",
        "**Assumptions:**\n",
        "\n",
        "+ Readings may be missing for extended periods due to communication problems with the sensors.\n",
        "\n",
        "+ Readings are collected do not fall precisely \"on the hour\". The are collected and recorded any time.\n",
        "\n",
        "+ For more precise results, estimate the value of the meter at precise timestamp, using linear interpolation from nearest readings.\n",
        "\n",
        "5. Compute the **estimated** value of each sensor meter for every hour and day of the month (in ascending order).\n",
        "\n",
        "6. Compute the **estimated** running total of the energy consumed so far. The value should be updated every hour."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdTj-7SD-67o"
      },
      "source": [
        "## Requeriments\n",
        "\n",
        "Solve each question using Structured Spark, either Dataframes or SQL or both."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81dR9BTgBg1s"
      },
      "source": [
        "---\n",
        "### Colab Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2O_3I3x1dbx"
      },
      "outputs": [],
      "source": [
        "#@title Install PySpark\n",
        "!pip install pyspark findspark --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jB8R09NjYJUW",
        "outputId": "1105ff36-0c63-46e1-86b5-e9d8559d7087"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "date;sensor;energy\n",
            "2024-02-01 00:00:00;D;2615.0\n"
          ]
        }
      ],
      "source": [
        "#@title Download the dataset\n",
        "\n",
        "!wget -q -O energy-readings.csv https://raw.githubusercontent.com/smduarte/spbd-2425/refs/heads/main/docs/labs/projs/energy-readings.csv\n",
        "!head -2 energy-readings.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zo41adHJYGs6",
        "outputId": "6548c301-91bb-45c7-9ff5-c61d5ae0f09a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- date: timestamp (nullable = true)\n",
            " |-- sensor: string (nullable = true)\n",
            " |-- energy: double (nullable = true)\n",
            "\n",
            "+-------------------+------+------+\n",
            "|               date|sensor|energy|\n",
            "+-------------------+------+------+\n",
            "|2024-02-01 00:00:00|     D|2615.0|\n",
            "|2024-02-01 00:00:18|     C|1098.8|\n",
            "|2024-02-01 00:00:25|     A| 650.5|\n",
            "|2024-02-01 00:00:33|     J| 966.7|\n",
            "|2024-02-01 00:00:42|     H|2145.4|\n",
            "+-------------------+------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "spark = SparkSession.builder.master('local[*]').appName('energy').getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext\n",
        "try :\n",
        "    readings = spark.read.csv('energy-readings.csv',\n",
        "                             sep =';', header=True, inferSchema=True)\n",
        "\n",
        "    readings.printSchema()\n",
        "\n",
        "\n",
        "    readings.show(5)\n",
        "except Exception as err:\n",
        "    print(err)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WKSuzI_Vybn"
      },
      "source": [
        "## Extract February readings\n",
        "\n",
        "Before staring any task, we decided to filter the data based on the timestamp to get all the readings from February and keep it in a separate DataFrame for the furhter use.\n",
        "\n",
        "For most tasks this is sufficient. However for task 5 and 6 more data is needed to perform the interpolation at the edges of the month."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvkXkeIWJzjN",
        "outputId": "43d291d0-a37e-416a-8c37-b29548489a7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------+------+------+\n",
            "|               date|sensor|energy|\n",
            "+-------------------+------+------+\n",
            "|2024-02-01 00:00:00|     D|2615.0|\n",
            "|2024-02-01 00:00:18|     C|1098.8|\n",
            "|2024-02-01 00:00:25|     A| 650.5|\n",
            "|2024-02-01 00:00:33|     J| 966.7|\n",
            "|2024-02-01 00:00:42|     H|2145.4|\n",
            "+-------------------+------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# extract readings from February\n",
        "readings_february = readings.filter(\"date >= date '2024-02-01' AND date < date '2024-03-01'\")\n",
        "readings_february.show(5)\n",
        "\n",
        "# save results\n",
        "readings_february.write.option(\"header\", True) \\\n",
        "    .option(\"delimiter\", \",\") \\\n",
        "    .mode(\"overwrite\") \\\n",
        "    .csv(\"readings_february.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhGsw_GJUv9S"
      },
      "source": [
        "## TASK 1: For the group of sensors: Compute the total energy consumed\n",
        "\n",
        "Our approach to this task was to take the readings from February, and for each sensor calculate the amount of energy used in the month of February (using the first and last reading of each sensor). Then, having the total energy used for each sensor, we summed it and got the total energy consumption in February."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mV8-vBIC7fDn",
        "outputId": "b7bdcd61-0093-4a06-d41b-58022cd4c16d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------------------------+\n",
            "|total_energy_consumption_february|\n",
            "+---------------------------------+\n",
            "|                           3106.8|\n",
            "+---------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# calculate the total energy consumption in February\n",
        "total_energy_consumption_february = readings_february.groupBy('sensor')\\\n",
        "                                                     .agg(round((max('energy') - min('energy')), 1).alias('energy_used'))\\\n",
        "                                                     .orderBy('sensor')\\\n",
        "                                                     .select(round(sum('energy_used'), 2).alias('total_energy_consumption_february'))\n",
        "\n",
        "total_energy_consumption_february.show()\n",
        "\n",
        "# save results\n",
        "total_energy_consumption_february.write.option(\"header\", True).option(\"delimiter\", \",\").mode(\"overwrite\").csv(\"T1_total_energy_consumption_february.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1BWsrMrisEU"
      },
      "source": [
        "## TASK 2: For the group of sensors: Compute the running total energy consumed so far for each day, inclusive\n",
        "\n",
        "This task was solved in two steps.\n",
        "\n",
        "Firstly, we extracted the initial energy that was measured on each sensor at the begining of February (taken as the first reading from that month). That marked our starting point for any further energy consumption calculations.\n",
        "The obtained DataFrame is shown below:\n",
        "\n",
        "```\n",
        "+------+---------------+\n",
        "|sensor|starting_energy|\n",
        "+------+---------------+\n",
        "|     A|          650.5|\n",
        "|     B|          627.5|\n",
        "|     C|         1098.8|\n",
        "|     D|         2615.0|\n",
        "|     E|         1874.0|\n",
        "|     F|          748.0|\n",
        "|     G|          833.7|\n",
        "|     H|         2145.4|\n",
        "|     I|          927.2|\n",
        "|     J|          966.7|\n",
        "|     K|          841.2|\n",
        "+------+---------------+\n",
        "```\n",
        "\n",
        "After that, for each sensor and for each day, we calculated the end-of-the-day energy consumption, which was an acumulated value over all previous days of February.\n",
        "Finally, for each day, we summed all the obtained values of all sensors and got the running daily energy consumption"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bR0NC7ez753G",
        "outputId": "45a6569e-efb0-4024-e616-b341279946c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----------------------------+\n",
            "|       day|running_daily_energy_february|\n",
            "+----------+-----------------------------+\n",
            "|2024-02-01|                        119.7|\n",
            "|2024-02-02|                        189.9|\n",
            "|2024-02-09|                       1104.9|\n",
            "|2024-02-10|                       1219.4|\n",
            "|2024-02-11|                       1337.3|\n",
            "|2024-02-12|                       1448.1|\n",
            "|2024-02-13|                       1560.8|\n",
            "|2024-02-14|                       1654.2|\n",
            "|2024-02-15|                       1735.4|\n",
            "|2024-02-16|                       1783.2|\n",
            "|2024-02-18|                       2023.4|\n",
            "|2024-02-19|                       2103.1|\n",
            "|2024-02-20|                       2187.4|\n",
            "|2024-02-21|                       2270.4|\n",
            "|2024-02-22|                       2347.0|\n",
            "|2024-02-23|                       2431.8|\n",
            "|2024-02-24|                       2575.4|\n",
            "|2024-02-25|                       2675.1|\n",
            "|2024-02-26|                       2767.7|\n",
            "|2024-02-27|                       2860.8|\n",
            "|2024-02-28|                       2974.3|\n",
            "|2024-02-29|                       3106.8|\n",
            "+----------+-----------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# get the first reading from each sensor\n",
        "starting_energy = readings_february.groupBy(\"sensor\")\\\n",
        "                                   .agg(min(\"energy\").alias(\"starting_energy\"))\\\n",
        "                                   .orderBy(\"sensor\")\n",
        "\n",
        "# calculate daily running energy consumption in February\n",
        "#         -> calculate each sensor's end-of-the-day_energy, substract the first reading and sum all sensors' results for each day\n",
        "daily_running_energy_consumption_february = readings_february.join(starting_energy, \"sensor\", \"left\")\\\n",
        "                                                             .withColumn(\"day\", to_date(\"date\"))\\\n",
        "                                                             .groupBy(\"day\", \"sensor\")\\\n",
        "                                                             .agg((max(\"energy\")-first(\"starting_energy\")).alias(\"end-of-the-day_energy\"))\\\n",
        "                                                             .groupBy(\"day\")\\\n",
        "                                                             .agg(round(sum(\"end-of-the-day_energy\"), 1).alias(\"running_daily_energy_february\"))\\\n",
        "                                                             .orderBy(\"day\")\n",
        "\n",
        "daily_running_energy_consumption_february.show(25)\n",
        "\n",
        "\n",
        "# save results\n",
        "daily_running_energy_consumption_february.write.option(\"header\", True).option(\"delimiter\", \",\").mode(\"overwrite\").csv(\"T2_daily_running_energy_consumption_february.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkT5k50MWOoE"
      },
      "source": [
        "## TASK 3 For each sensor, separately: Compute the total energy consumed and the average energy consumption per day\n",
        "\n",
        "Our approach to this task was to calculate the energy consumed per day for each sensor by grouping the data by day and sensor and then compute max(energy) - min(energy) for each day to obtain the amount of energy consumped per day.\n",
        "\n",
        "To obtain the average consumption per day for each sensor, we used the results from the the first step and took the average of all days of febraury for each sensor.\n",
        "\n",
        "This means, the result contains the energy consumed per day for each sensor and day in february and as well in a new column the average consumed per day. <br/>\n",
        "\n",
        "**NOTE** that the average is the same value for the same sensor at different days since it represents the average consumption per day in february.\n",
        "\n",
        "What one can read from this is the days of the month where more or less than the average enegry was consumned per sensor.\n",
        "\n",
        "\n",
        "The Daily average per sensor DataFrame for february looks as follows:\n",
        "\n",
        "```\n",
        "+------+----------------+\n",
        "|sensor|avg_daily_energy|\n",
        "+------+----------------+\n",
        "|     A|             5.1|\n",
        "|     B|             3.3|\n",
        "|     C|             8.0|\n",
        "|     D|            15.5|\n",
        "|     E|            13.0|\n",
        "|     F|             4.4|\n",
        "|     G|             4.8|\n",
        "|     H|            13.2|\n",
        "|     I|             9.4|\n",
        "|     J|             6.4|\n",
        "|     K|             6.7|\n",
        "+------+----------------+\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dajlrdho7_-q",
        "outputId": "55e04407-3bfa-48ff-9e20-dd85b00cdcb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+----------+------------+----------------+\n",
            "|sensor|       day|daily_energy|avg_daily_energy|\n",
            "+------+----------+------------+----------------+\n",
            "|     A|2024-02-01|         8.1|             5.1|\n",
            "|     B|2024-02-01|         4.2|             3.3|\n",
            "|     C|2024-02-01|         9.7|             8.0|\n",
            "|     D|2024-02-01|        12.9|            15.5|\n",
            "|     E|2024-02-01|        16.1|            13.0|\n",
            "|     F|2024-02-01|        11.0|             4.4|\n",
            "|     G|2024-02-01|         3.3|             4.8|\n",
            "|     H|2024-02-01|        23.5|            13.2|\n",
            "|     I|2024-02-01|        19.9|             9.4|\n",
            "|     J|2024-02-01|         2.6|             6.4|\n",
            "|     K|2024-02-01|         8.4|             6.7|\n",
            "|     A|2024-02-02|         4.8|             5.1|\n",
            "|     B|2024-02-02|         4.6|             3.3|\n",
            "|     C|2024-02-02|         1.6|             8.0|\n",
            "|     D|2024-02-02|         5.9|            15.5|\n",
            "|     E|2024-02-02|        10.1|            13.0|\n",
            "|     F|2024-02-02|         6.5|             4.4|\n",
            "|     G|2024-02-02|         4.1|             4.8|\n",
            "|     H|2024-02-02|         6.2|            13.2|\n",
            "|     I|2024-02-02|        12.5|             9.4|\n",
            "+------+----------+------------+----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Compute the daily consumption per sensor\n",
        "daily_total_energy = readings_february\\\n",
        "                          .withColumn(\"day\", to_date(\"date\"))\\\n",
        "                          .groupBy(\"day\", \"sensor\")\\\n",
        "                          .agg(round(max(\"energy\") - min(\"energy\"), 1).alias(\"daily_energy\"))\\\n",
        "                          .orderBy(\"day\", \"sensor\")\n",
        "\n",
        "# compute the daily average consumption\n",
        "daily_avg_energy = daily_total_energy\\\n",
        "                          .groupBy(\"sensor\")\\\n",
        "                          .agg(round(avg(\"daily_energy\"), 1)\\\n",
        "                          .alias(\"avg_daily_energy\"))\\\n",
        "                          .orderBy(\"sensor\")\n",
        "\n",
        "\n",
        "# Join the results to obtain a single datafram containing the results daily consumption as well as the average consumption\n",
        "joined_results = daily_total_energy\\\n",
        "                          .join(daily_avg_energy, \"sensor\")\\\n",
        "                          .orderBy(\"day\", \"sensor\")\n",
        "\n",
        "joined_results.show(20)\n",
        "\n",
        "# save results\n",
        "joined_results.write.option(\"header\", True).option(\"delimiter\", \",\").mode(\"overwrite\").csv(\"T3_daily_total_and_average_energy.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrihB6w8Xyes"
      },
      "source": [
        "### TASK 4 For each sensor, separately: Compute the day of the month with minimum and maximum energy consumption.\n",
        "\n",
        "Our approach to this task is to first compute the daily consumption per day as in the previous task, and then take the minimum and maximum day for each sensor.\n",
        "\n",
        "Due to aggreagtion, we lose some information that we have to get back by joining again with the original readings from february.\n",
        "\n",
        "It is possible, that a sensor appears twice in the data. This happens when a sensor has the same minimum or maximum energy consumption measurment for different days.\n",
        "\n",
        "\n",
        "```\n",
        "+------+----------+--------------+----------+--------------+\n",
        "|sensor|max_energy|max_energy_day|min_energy|min_energy_day|\n",
        "+------+----------+--------------+----------+--------------+\n",
        "|     A|       8.1|    2024-02-01|       0.8|    2024-02-24|\n",
        "|     B|       9.9|    2024-02-12|       0.1|    2024-02-09|\n",
        "|     C|      14.0|    2024-02-11|       1.6|    2024-02-23|\n",
        "|     C|      14.0|    2024-02-11|       1.6|    2024-02-02|\n",
        "|   ...|       ...|           ...|       ...|           ...|\n",
        "|     I|      20.7|    2024-02-29|       0.5|    2024-02-18|\n",
        "|     J|      10.0|    2024-02-11|       1.7|    2024-02-18|\n",
        "|     K|      10.2|    2024-02-11|       1.2|    2024-02-16|\n",
        "+------+----------+--------------+----------+--------------+\n",
        "```\n",
        "For sensor C it becomes visible, that there are two days with minimum enegry consumption. Thats why the sensor appears twice in the result data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGcbd4CX8CZc",
        "outputId": "c9abc204-b6ad-4cb6-e7f4-5a6f118a754e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+----------+--------------+----------+--------------+\n",
            "|sensor|max_energy|max_energy_day|min_energy|min_energy_day|\n",
            "+------+----------+--------------+----------+--------------+\n",
            "|     A|       8.1|    2024-02-01|       0.8|    2024-02-24|\n",
            "|     B|       9.9|    2024-02-12|       0.1|    2024-02-09|\n",
            "|     C|      14.0|    2024-02-11|       1.6|    2024-02-23|\n",
            "|     C|      14.0|    2024-02-11|       1.6|    2024-02-02|\n",
            "|     D|      26.4|    2024-02-29|       5.7|    2024-02-16|\n",
            "|     E|      20.6|    2024-02-13|       4.7|    2024-02-23|\n",
            "|     F|      12.9|    2024-02-29|       0.8|    2024-02-18|\n",
            "|     G|       9.3|    2024-02-10|       0.7|    2024-02-09|\n",
            "|     H|      26.1|    2024-02-28|       2.1|    2024-02-26|\n",
            "|     I|      20.7|    2024-02-29|       0.5|    2024-02-18|\n",
            "|     J|      10.0|    2024-02-11|       1.7|    2024-02-18|\n",
            "|     K|      10.2|    2024-02-11|       1.2|    2024-02-16|\n",
            "+------+----------+--------------+----------+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# compute the daiyl enegry consumption for each sensor\n",
        "daily_total_energy = readings_february\\\n",
        "                          .withColumn(\"day\", to_date(\"date\"))\\\n",
        "                          .groupBy(\"day\", \"sensor\")\\\n",
        "                          .agg(round(max(\"energy\") - min(\"energy\"), 1).alias(\"daily_energy\"))\\\n",
        "                          .orderBy(\"day\", \"sensor\")\n",
        "\n",
        "# compute the min and minimum and maxiumum daily energy consumption for each sensor\n",
        "# Renaming the Sensor column is necessary to avoid naming conficts when joining\n",
        "min_max_energy = daily_total_energy\\\n",
        "                          .groupBy(\"sensor\")\\\n",
        "                          .agg(\n",
        "                              min(\"daily_energy\").alias(\"min_energy\"),\n",
        "                              max(\"daily_energy\").alias(\"max_energy\"),\n",
        "                          ).withColumnRenamed(\"sensor\", \"sensor_min_max\")\n",
        "\n",
        "# Join back with the daily data to obtain the dates for min and max\n",
        "# Selectig only necessary columns is improtant to avoid naming conflicts bewteen the dataframes.\n",
        "joined_date_min_max = min_max_energy\\\n",
        "                          .join(daily_total_energy,\n",
        "                            (min_max_energy.max_energy == daily_total_energy.daily_energy) &\n",
        "                            (min_max_energy.sensor_min_max == daily_total_energy.sensor), \"left\"\n",
        "                          )\\\n",
        "                          .dropDuplicates()\\\n",
        "                          .select(\"sensor_min_max\", \"max_energy\", \"day\", \"min_energy\")\\\n",
        "                          .withColumnRenamed(\"day\", \"max_energy_day\")\\\n",
        "                          .join(daily_total_energy,\n",
        "                            (min_max_energy.min_energy == daily_total_energy.daily_energy) &\n",
        "                            (min_max_energy.sensor_min_max == daily_total_energy.sensor), \"left\"\n",
        "                          )\\\n",
        "                          .dropDuplicates()\\\n",
        "                          .select(\"sensor\", \"max_energy\", \"max_energy_day\", \"min_energy\", \"day\")\\\n",
        "                          .withColumnRenamed(\"day\", \"min_energy_day\")\\\n",
        "                          .orderBy(\"sensor\")\n",
        "\n",
        "joined_date_min_max.show()\n",
        "\n",
        "# save results\n",
        "joined_date_min_max.write.option(\"header\", True).option(\"delimiter\", \",\").mode(\"overwrite\").csv(\"T4_date_of_min_max_energy_consumption.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlgi9Ha_fwaK"
      },
      "source": [
        "## TASK 5 and 6 Setup and utils functions\n",
        "\n",
        "\n",
        "### Utils funcitons:\n",
        "**interpolate (UDF):** interpolates the energy value between two given dates and values. The interpolation is based on a simple linear interpolation function.\n",
        "\n",
        "```math\n",
        "interpolated_value = energy_measure_1 + (target_seconds * (energy_measure_2 - energy_measure_1) / total_seconds)\n",
        "\n",
        "where:\n",
        "energy_measure_1 is the energy measure before\n",
        "target_seconds is the the distance in seconds between the timestamp of the measurement before and the timestamp we want to interpolate\n",
        "energy_measure_2 is the energy measure after\n",
        "total_seconds is the distnace in seconds between energy_measure_1 and energy_measure_2\n",
        "```\n",
        "\n",
        "\n",
        "**generate_hourly_timestamps:** Generates a series of equidistnat timestamps between a given start and end date. The timestamps are always produced for each full hour. E.g.\n",
        "```math\n",
        "start_time: date = 2024-02-01 00:00:00\n",
        "end_time: date = 2024-02-02 00:00:00\n",
        "\n",
        "the funciton would produce a dataframe with the fillowing rows:\n",
        "\n",
        "    2024-02-01 00:00:00\n",
        "    2024-02-01 01:00:00\n",
        "    ...\n",
        "    2024-02-01 23:00:00\n",
        "    2024-02-02 00:00:00\n",
        "```\n",
        "\n",
        "### Interpretation of the tasks 5 and 6\n",
        "**5.** We understand task 5 as follows: We have to show the interpolated value of each sensor for each full hour of every day in february.\n",
        "\n",
        "**6.** We understand tasks 6 as follows: We are asked to provide the running total for each sensor and hour based on the interpolated the data. The output is one dataframe showing the running total of every hour of the day of the month febraury.\n",
        "\n",
        "Therefore we can reuse the dataframe obtain in task five for further processing\n",
        "\n",
        "**Difference** The key difference between the tasks is, that task 5 only requires to interpolate the missing data for hours and days, while task 6 asks to proive the running total for february.\n",
        "\n",
        "\n",
        "## Approach Task 5:\n",
        "The overall approach to this task was to use the above described utility function to create artificial readings for each full hour, and then interpolate their enegry measurements by using the closest real merasurments.\n",
        "\n",
        "### 1. step:\n",
        "Define the start and end time of the interpolation period. In this case its the whole month of february for each distinct sensors.\n",
        "\n",
        "```\n",
        "+------+-------------------+-------------------+\n",
        "|sensor|         start_time|           end_time|\n",
        "+------+-------------------+-------------------+\n",
        "|     K|2024-02-01 00:00:00|2024-03-01 00:00:00|\n",
        "|     F|2024-02-01 00:00:00|2024-03-01 00:00:00|\n",
        "|     E|2024-02-01 00:00:00|2024-03-01 00:00:00|\n",
        "|     B|2024-02-01 00:00:00|2024-03-01 00:00:00|\n",
        "|     D|2024-02-01 00:00:00|2024-03-01 00:00:00|\n",
        "|     C|2024-02-01 00:00:00|2024-03-01 00:00:00|\n",
        "|     J|2024-02-01 00:00:00|2024-03-01 00:00:00|\n",
        "|     A|2024-02-01 00:00:00|2024-03-01 00:00:00|\n",
        "|     G|2024-02-01 00:00:00|2024-03-01 00:00:00|\n",
        "|     I|2024-02-01 00:00:00|2024-03-01 00:00:00|\n",
        "|     H|2024-02-01 00:00:00|2024-03-01 00:00:00|\n",
        "+------+-------------------+-------------------+\n",
        "```\n",
        "### 2. step: creating equidistant timestamps\n",
        "Then, we generated the timestamps for each full hour and exploded them. This is necessary to capture the estimation for the whole hours and also the whole day of energy consumption. The energy value is always set to NULL since this is what we want to estimate.\n",
        "\n",
        "### 3. step: union with real measurements\n",
        "In the next step we formed a union of the real measurements with the generated equidistnat timestamps we generated. This provides a dataframe that contains all real measurements and timestamps as well as all the generated ones that have energy = NULL.\n",
        "\n",
        "### 4. step: define a window function.\n",
        "we defined a window function that partitions by sensor and orders by timestamp. This is necessary to interpolate the data for each sensor separately and also keep the order of the timestampss\n",
        "\n",
        "### 5. step apply window function to obtain valid previous and next reading:\n",
        "apply the window function. We applied the window function in a way, that for every row we added 4 new columns. First we added the last timetamp and energy reading that happened before the current reading but with the constraint that the energy reading cannot be NULL. This ensures, that for each row, we get the first previous real energy reading. We did the same for the next timestamp and real energy reading. Then we filtered all NULL values to obtain a dataframe that containes the following information:\n",
        "\n",
        "```\n",
        "+-------------------+------+------+--------------------+--------------------+-----------------+-----------------+\n",
        "|               date|sensor|energy|prev_valid_timestamp|next_valid_timestamp|prev_energy_level|next_energy_level|\n",
        "+-------------------+------+------+--------------------+--------------------+-----------------+-----------------+\n",
        "|2024-02-01 00:00:00|     B|  NULL|                NULL| 2024-02-01 00:03:32|             NULL|            627.5|\n",
        "|2024-02-01 01:00:00|     B|  NULL| 2024-02-01 00:57:48| 2024-02-01 01:02:56|            627.6|            627.6|\n",
        "|2024-02-01 02:00:00|     B|  NULL| 2024-02-01 01:55:45| 2024-02-01 02:00:53|            627.8|            627.8|\n",
        "|2024-02-01 03:00:00|     B|  NULL| 2024-02-01 02:59:33| 2024-02-01 03:04:41|            627.9|            627.9|\n",
        "|2024-02-01 04:00:00|     B|  NULL| 2024-02-01 03:56:24| 2024-02-01 04:01:32|            628.0|            628.0|\n",
        "|2024-02-01 05:00:00|     B|  NULL| 2024-02-01 04:55:26| 2024-02-01 05:00:34|            628.2|            628.2|\n",
        "|2024-02-01 06:00:00|     B|  NULL| 2024-02-01 05:57:03| 2024-02-01 06:02:11|            628.2|            628.2|\n",
        "|2024-02-01 07:00:00|     B|  NULL| 2024-02-01 06:58:40| 2024-02-01 07:03:48|            628.2|            628.2|\n",
        "|2024-02-01 08:00:00|     B|  NULL| 2024-02-01 07:55:30| 2024-02-01 08:00:38|            628.3|            628.3|\n",
        "|2024-02-01 09:00:00|     B|  NULL| 2024-02-01 08:57:07| 2024-02-01 09:02:15|            628.3|            628.3|\n",
        "|2024-02-01 10:00:00|     B|  NULL| 2024-02-01 09:58:43| 2024-02-01 10:03:51|            628.3|            628.3|\n",
        "|2024-02-01 11:00:00|     B|  NULL| 2024-02-01 10:57:02| 2024-02-01 11:02:10|            628.5|            628.5|\n",
        "|2024-02-01 12:00:00|     B|  NULL| 2024-02-01 11:58:38| 2024-02-01 12:01:12|            628.6|            628.7|\n",
        "|2024-02-01 13:00:00|     B|  NULL| 2024-02-01 12:55:51| 2024-02-01 13:00:59|            628.8|            628.8|\n",
        "|2024-02-01 14:00:00|     B|  NULL| 2024-02-01 13:57:49| 2024-02-01 14:02:57|            629.0|            629.0|\n",
        "|2024-02-01 15:00:00|     B|  NULL| 2024-02-01 14:55:02| 2024-02-01 15:00:10|            629.1|            629.1|\n",
        "|2024-02-01 16:00:00|     B|  NULL| 2024-02-01 15:58:06| 2024-02-01 16:03:15|            629.3|            629.3|\n",
        "|2024-02-01 17:00:00|     B|  NULL| 2024-02-01 16:08:23| 2024-02-01 17:11:41|            629.5|            629.6|\n",
        "|2024-02-01 18:00:00|     B|  NULL| 2024-02-01 17:56:04| 2024-02-01 18:01:12|            630.7|            630.7|\n",
        "|2024-02-01 19:00:00|     B|  NULL| 2024-02-01 18:58:47| 2024-02-01 19:02:27|            630.9|            631.0|\n",
        "+-------------------+------+------+--------------------+--------------------+-----------------+-----------------+\n",
        "```\n",
        "prev_valid_timestamp refers to the first valid timestamp before a current timestamp and next_valid_timestamp to the next valid after a current timestamp. energy values are the according measuremnts. date is the timestamp we want to interpolate. This dataframe contains all information to interpolate the missing energy values for full hours.\n",
        "\n",
        "**NOTE** Since the data has no measurements before february, the first timestamp in the data is in february. This means, that there is no previous timestamp for 2024-02-01 00:00:00. this can be seen in the table as NULL in the prev_valid_timestamp and prev_valid_energy_reading.\n",
        "\n",
        "The interploation function catches these edge cases and provides the reading of the next_valid_date as result instead. This means the approximation of 2024-02-01 00:00:00 is done by using the value of the very first reading of february.\n",
        "\n",
        "### 6. step: interpolate\n",
        "Now that we collected all data needed, we can interpolate the missing energy measurement value by using the first valid previous and first valid next timestamp as well as the energy measurements to obtain the interpolated value for each hour for every day of the month february."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBj0zeY1f2BC"
      },
      "outputs": [],
      "source": [
        "# Define a UDF as interpolation function between two dates\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType, FloatType\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "def interpolate(date_1, energy_measure_1, date_2, energy_measure_2, date_to_interpolate):\n",
        "    \"\"\"\n",
        "    Interpolates the value at a specific time between two timestamps and corresponding energy values.\n",
        "\n",
        "    Parameters:\n",
        "    date_1: Timestamp of the last measurement of the previous day\n",
        "    energy_measure_1: The energy measurement of the previous day at the timestamp\n",
        "    date_2: Timestamp of the first measurement of the current day\n",
        "    energy_measure_2: The energy measurement of the current day at the timestamp\n",
        "    date_to_interpolate: The timestamp of the date to interpolate the energy values at\n",
        "\n",
        "    e.g:\n",
        "    date_1 = datetime.strptime('2019-02-01-23-50-00', '%Y-%m-%d-%H-%M-%S')\n",
        "    date_2 = datetime.strptime('2019-02-02-00-10-00', '%Y-%m-%d-%H-%M-%S')\n",
        "    target = datetime.strptime('2019-02-02-00-00-00', '%Y-%m-%d-%H-%M-%S')\n",
        "\n",
        "\n",
        "    energy_measure_1 = 1\n",
        "    energy_measure_2 = 3\n",
        "\n",
        "    expected return = interpolate(date_1, energy_measure_1, date_2, energy_measure_2, target) = 2\n",
        "\n",
        "    Returns:\n",
        "    Interpolated value at 00:00 Timestamp, if applicable; otherwise None.\n",
        "    \"\"\"\n",
        "    # ensure that neihter date 1 nor date 2 is not available\n",
        "    if date_1 is None and date_2 is not None: return energy_measure_2\n",
        "    if date_1 is not None and date_2 is  None: return energy_measure_1\n",
        "\n",
        "    # ensure that date_1 is before date_2\n",
        "    if date_1 > date_2: Exception(\"Date 1 cannot be greater than date 2!\")\n",
        "\n",
        "    # check that interpolation date is not on of the gien prev or next dates\n",
        "    if date_2 == date_to_interpolate: return energy_measure_2\n",
        "    if date_1 == date_to_interpolate: return energy_measure_1\n",
        "\n",
        "    # Calculate total seconds between the two given measurements\n",
        "    total_seconds = (date_2 - date_1).total_seconds()\n",
        "\n",
        "    # Calculate the seconds from date_1 to the date to be interpolated\n",
        "    target_seconds = (date_to_interpolate - date_1).total_seconds()\n",
        "\n",
        "    # Perform linear interpolation\n",
        "    interpolated_value = energy_measure_1 + (target_seconds * (energy_measure_2 - energy_measure_1) / total_seconds)\n",
        "\n",
        "    return interpolated_value\n",
        "\n",
        "# Convert the interpolation function to User Defined Function UDF\n",
        "interpolate_udf = udf(lambda a, b, c, d, e: interpolate(a, b, c, d, e), StringType())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HinMJ7XgZOJk"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import explode, sequence, date_trunc, col, expr, lit\n",
        "\n",
        "def generate_hourly_timestamps(df, start_col, end_col):\n",
        "    \"\"\"\n",
        "    Generate and explode houlry timestamps always at the exact hour between start and end time.\n",
        "    e.g:\n",
        "    2024-02-03 00:00:00\n",
        "    2024-02-03 01:00:00\n",
        "    2024-02-03 02:00:00\n",
        "    ...\n",
        "    2024-02-03 23:00:00\n",
        "    \"\"\"\n",
        "    return df.withColumn('date', explode(\n",
        "            sequence(\n",
        "                date_trunc('hour', col(start_col)), date_trunc('hour', col(end_col)), expr('INTERVAL 1 HOUR')\n",
        "            )\n",
        "        )\n",
        "    ).withColumn('energy', lit(None))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chxycakz0bqY"
      },
      "source": [
        "To handle edge cases, the february redings used in the previous tasks are not sufficient. Therefore a new february extended DataFrame is created that contains more data outside of the month february to ensure propper interpolation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qd3nTw0104Wm",
        "outputId": "bd921b96-c0e1-4b7b-8323-1dfad9c099c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------+------+------+\n",
            "|               date|sensor|energy|\n",
            "+-------------------+------+------+\n",
            "|2024-02-01 00:00:25|     A| 650.5|\n",
            "|2024-02-01 00:05:34|     A| 650.5|\n",
            "|2024-02-01 00:10:42|     A| 650.5|\n",
            "|2024-02-01 00:15:50|     A| 650.5|\n",
            "|2024-02-01 00:20:58|     A| 650.5|\n",
            "+-------------------+------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# extract extended readings from February\n",
        "readings_february_extended = readings\\\n",
        "                .filter(\"date >= date '2024-01-01' AND date <= date '2024-03-05'\")\\\n",
        "                .orderBy(\"sensor\", \"date\")\n",
        "\n",
        "readings_february_extended.show(5)\n",
        "\n",
        "# save results\n",
        "readings_february_extended.write.option(\"header\", True) \\\n",
        "    .option(\"delimiter\", \",\") \\\n",
        "    .mode(\"overwrite\") \\\n",
        "    .csv(\"readings_february_extended.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3XBjDGpx4RI",
        "outputId": "8af5887c-907a-4157-d9ac-e09c7d40bb95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------+------+-------------------+\n",
            "|               date|sensor|interploated_energy|\n",
            "+-------------------+------+-------------------+\n",
            "|2024-02-01 00:00:00|     A|              650.5|\n",
            "|2024-02-01 00:00:00|     B|              627.5|\n",
            "|2024-02-01 00:00:00|     C|             1098.8|\n",
            "|2024-02-01 00:00:00|     D|             2615.0|\n",
            "|2024-02-01 00:00:00|     E|             1874.0|\n",
            "|2024-02-01 00:00:00|     F|              748.0|\n",
            "|2024-02-01 00:00:00|     G|              833.7|\n",
            "|2024-02-01 00:00:00|     H|             2145.4|\n",
            "|2024-02-01 00:00:00|     I|              927.2|\n",
            "|2024-02-01 00:00:00|     J|              966.7|\n",
            "|2024-02-01 00:00:00|     K|              841.2|\n",
            "|2024-02-01 01:00:00|     A|              650.5|\n",
            "|2024-02-01 01:00:00|     B|              627.6|\n",
            "|2024-02-01 01:00:00|     C|             1098.8|\n",
            "|2024-02-01 01:00:00|     D|             2616.5|\n",
            "|2024-02-01 01:00:00|     E|             1875.0|\n",
            "|2024-02-01 01:00:00|     F|              748.7|\n",
            "|2024-02-01 01:00:00|     G|              833.8|\n",
            "|2024-02-01 01:00:00|     H|             2146.9|\n",
            "|2024-02-01 01:00:00|     I|              927.2|\n",
            "+-------------------+------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@title 5. For each sensor, separately, with estimations: Compute the estimated value of each sensor meter for every hour and day of the month (in ascending order)\n",
        "\n",
        "\n",
        "# STEP 1: generaete a dataframe that contains each sensor once and then add the start and endtime for february\n",
        "distinct_sensors = readings_february_extended.select(\"sensor\")\\\n",
        "                .distinct()\\\n",
        "                .withColumn('start_time', lit(datetime(2024,2,1,00,00,00)))\\\n",
        "                .withColumn('end_time', lit(datetime(2024,3,1,00,00,00)))\n",
        "\n",
        "\n",
        "# STEP 2: generate intervals of 1 hour always to the full hour\n",
        "df_hourly = generate_hourly_timestamps(distinct_sensors, \"start_time\", \"end_time\")\\\n",
        "                .select(\"date\", \"sensor\", \"energy\")\n",
        "\n",
        "# STEP 3: add the interval to the original energy dataframe\n",
        "unified_df = readings_february_extended.union(df_hourly).orderBy(\"sensor\", 'date')\n",
        "\n",
        "\n",
        "# STEP 4: Define the window specification ordered by timestamp and partitioned by sensor\n",
        "window_spec = Window.partitionBy(\"sensor\").orderBy(\"date\")\n",
        "\n",
        "# STEP 5: Apply window to create new columns with previous and next non-null energy readings and timestanps\n",
        "df_with_bounds = unified_df\\\n",
        "                .withColumn('prev_valid_timestamp', last(when(col('energy').isNotNull(), col('date')), ignorenulls=True)\\\n",
        "                            .over(window_spec.rowsBetween(Window.unboundedPreceding, -1)))\\\n",
        "                .withColumn('next_valid_timestamp',first(when(col('energy').isNotNull(), col('date')),ignorenulls=True)\\\n",
        "                            .over(window_spec.rowsBetween(1, Window.unboundedFollowing)))\\\n",
        "                .withColumn('prev_energy_level',last('energy', ignorenulls=True)\\\n",
        "                            .over(window_spec.rowsBetween(Window.unboundedPreceding, -1)))\\\n",
        "                .withColumn('next_energy_level', first('energy', ignorenulls=True)\\\n",
        "                            .over(window_spec.rowsBetween(1, Window.unboundedFollowing)))\\\n",
        "                .filter(col('energy').isNull())\n",
        "\n",
        "# STEP 6: Add interpolation\n",
        "interpolated_df = df_with_bounds.withColumn(\n",
        "                'interpolated_energy', round(interpolate_udf(\n",
        "                    col('prev_valid_timestamp'),\n",
        "                    col('prev_energy_level'),\n",
        "                    col('next_valid_timestamp'),\n",
        "                    col('next_energy_level'),\n",
        "                    col('date')\n",
        "                ), 1))\\\n",
        "                .drop(\n",
        "                    'prev_valid_timestamp',\n",
        "                    'next_valid_timestamp',\n",
        "                    'prev_energy_level',\n",
        "                    'next_energy_level',\n",
        "                    'energy'\n",
        "                )\\\n",
        "                .orderBy(\"date\", \"sensor\")\n",
        "\n",
        "# show results\n",
        "interpolated_df.show()\n",
        "\n",
        "# save results\n",
        "interpolated_df.write.option(\"header\", True).option(\"delimiter\", \",\").mode(\"overwrite\").csv(\"T5_interpolated_energy_readings.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN16RDWo1n18"
      },
      "source": [
        "## TASK 6: Compute the estimated running total of the energy consumed so far. The value should be updated every hour.\n",
        "\n",
        "Our approach to this taks was to reuse the results of the interpolation of the previous task and continue processing them to obtain the estimated running value for each hour.\n",
        "\n",
        "As a first step we again calculated the initial reading of february for each sensor as in task 2.\n",
        "\n",
        "Then we joined the interpolated data with the initial readings to then subtract the initial reading from every energy reading entry in the joined dataframe.\n",
        "\n",
        "The outcome is an (estimated) interpolated running total for the month february"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yunX6A2sFXkq",
        "outputId": "fa1e4670-c224-48bc-8722-3c57e26b75d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+-------------------+-------------------+-----------------------------------+\n",
            "|sensor|               date|interploated_energy|interpolated_running_total_february|\n",
            "+------+-------------------+-------------------+-----------------------------------+\n",
            "|     A|2024-02-01 00:00:00|              650.5|                                0.0|\n",
            "|     A|2024-02-01 01:00:00|              650.5|                                0.0|\n",
            "|     A|2024-02-01 02:00:00|              650.6|                                0.1|\n",
            "|     A|2024-02-01 03:00:00|              650.6|                                0.1|\n",
            "|     A|2024-02-01 04:00:00|              650.6|                                0.1|\n",
            "|     A|2024-02-01 05:00:00|              650.9|                                0.4|\n",
            "|     A|2024-02-01 06:00:00|              651.1|                                0.6|\n",
            "|     A|2024-02-01 07:00:00|              651.1|                                0.6|\n",
            "|     A|2024-02-01 08:00:00|              651.1|                                0.6|\n",
            "|     A|2024-02-01 09:00:00|              651.2|                                0.7|\n",
            "|     A|2024-02-01 10:00:00|              651.2|                                0.7|\n",
            "|     A|2024-02-01 11:00:00|              652.1|                                1.6|\n",
            "|     A|2024-02-01 12:00:00|              652.2|                                1.7|\n",
            "|     A|2024-02-01 13:00:00|              653.2|                                2.7|\n",
            "|     A|2024-02-01 14:00:00|              654.4|                                3.9|\n",
            "|     A|2024-02-01 15:00:00|              654.5|                                4.0|\n",
            "|     A|2024-02-01 16:00:00|              654.5|                                4.0|\n",
            "|     A|2024-02-01 17:00:00|              654.6|                                4.1|\n",
            "|     A|2024-02-01 18:00:00|              654.6|                                4.1|\n",
            "|     A|2024-02-01 19:00:00|              654.7|                                4.2|\n",
            "+------+-------------------+-------------------+-----------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# get the first reading for each sensor\n",
        "initial_reading_df = interpolated_df.groupBy(\"sensor\").agg(min(\"interpolated_energy\").alias(\"initial_energy\"))\n",
        "\n",
        "# reuse interpolated data from preious task. Task. 5 must run first\n",
        "interpolated_running_df = interpolated_df.join(initial_reading_df, \"sensor\", \"left\")\\\n",
        "                .withColumn(\"interpolated_running_total_february\", round(col(\"interpolated_energy\") - col(\"initial_energy\"), 1))\\\n",
        "                .drop(\"initial_energy\", \"interploated_running_total\")\\\n",
        "                .orderBy(\"sensor\", \"date\")\n",
        "\n",
        "# compute the hourly consumption\n",
        "interpolated_running_df.show()\n",
        "\n",
        "# save results\n",
        "interpolated_running_df.write.option(\"header\", True).option(\"delimiter\", \",\").mode(\"overwrite\").csv(\"T6_interpolated_running_total.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
